{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from transformers import Pipeline, pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Prediction(BaseModel):\n",
    "    generated_text: str\n",
    "\n",
    "\n",
    "class Predictions(BaseModel):\n",
    "    results: list[Prediction]\n",
    "\n",
    "\n",
    "class Event(BaseModel):\n",
    "    title: str\n",
    "    text: str"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator: Pipeline = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "# set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def builder(prompt: str) -> list[Event]:\n",
    "#     events: list[Event] = []\n",
    "#\n",
    "#     titles: Predictions = Predictions.parse_obj({\"results\": generator(prompt, max_length=10, num_return_sequences=30)})\n",
    "#\n",
    "#     for title in titles.results:\n",
    "#         title_str: str = title.generated_text\n",
    "#         texts: Predictions = Predictions.parse_obj({\"results\": generator(title_str, max_length=120, num_return_sequences=10)})\n",
    "#         for text in texts.results:\n",
    "#             text_str = text.generated_text\n",
    "#             event = Event(title=title_str, text=text_str)\n",
    "#             events.append(event)\n",
    "#     return events"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# events: list[Event] = builder('raccoon horror')\n",
    "# for event in events:\n",
    "#     print(\n",
    "#         event.title + '\\n',\n",
    "#         event.text + '\\n',\n",
    "#         \"\\n\"\n",
    "#     )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts: list[str] = [\"raccoon\"]\n",
    "for prompt in prompts:\n",
    "    samples: Predictions = Predictions.parse_obj(\n",
    "        {\"results\": generator(prompt, max_length=200, num_return_sequences=300)}\n",
    "    )\n",
    "    # for event in samples.results:\n",
    "    # print(event.generated_text)\n",
    "    # print(\n",
    "    #     event.title + '\\n',\n",
    "    #     event.text + '\\n',\n",
    "    #     \"\\n\"\n",
    "    # )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import traceback\n",
    "from typing import Any, Optional\n",
    "import string\n",
    "\n",
    "\n",
    "class LineScore(BaseModel):\n",
    "    text: str\n",
    "    length: Optional[int]\n",
    "    # float (0->1) percentage of the string\n",
    "    lower: Optional[float]\n",
    "    upper: Optional[float]\n",
    "    numeric: Optional[float]\n",
    "    white_space: Optional[float]\n",
    "    punc: Optional[float]\n",
    "    total: Optional[float]\n",
    "    newline: Optional[float]\n",
    "\n",
    "    def __init__(self, **data: Any):\n",
    "        super().__init__(**data)\n",
    "\n",
    "        self.length: int = len(self.text)\n",
    "        white_space_count: int = len([i for i in self.text if i.isspace()])\n",
    "        punc_count: int = len([i for i in self.text if i in string.punctuation])\n",
    "        digits_count: int = len([i for i in self.text if i in string.digits])\n",
    "        lower_count: int = len([i for i in self.text if i in string.ascii_lowercase])\n",
    "        upper_count: int = len([i for i in self.text if i in string.ascii_uppercase])\n",
    "        newline_count: int = len([i for i in self.text if i == \"\\n\"])\n",
    "\n",
    "        self.lower = lower_count / self.length\n",
    "        self.upper = upper_count / self.length\n",
    "        self.numeric = digits_count / self.length\n",
    "        self.white_space = white_space_count / self.length\n",
    "        self.punc = punc_count / self.length\n",
    "        self.newline = newline_count / self.length\n",
    "\n",
    "        try:\n",
    "            self.total = self.lower + self.upper + self.numeric + self.white_space + self.punc + self.newline\n",
    "        except Exception as error:\n",
    "            traceback.print_exc()\n",
    "            print(self.text)\n",
    "            raise error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\"text\", \"length\", \"lower\", \"upper\", \"numeric\", \"white_space\", \"punc\", \"total\", \"newline\"]\n",
    "data_dict = {}\n",
    "for event in samples.results:\n",
    "    # print(event.generated_text)\n",
    "    score = LineScore(text=event.generated_text)\n",
    "    score_dict = score.dict()\n",
    "    # print(score_dict)\n",
    "    for column in columns:\n",
    "        if column not in data_dict:\n",
    "            data_dict[column] = [score_dict[column]]\n",
    "        else:\n",
    "            data_dict[column].append(score_dict[column])\n",
    "# print(data_dict)\n",
    "score_df = pd.DataFrame.from_dict(data_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Filter our entries with punctuation above the group median"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filtered_df = score_df[score_df['punc'] <= score_df['punc'].median()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Excluded due to high occurrence of punctuation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "by quantile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_quantile = score_df.loc[:, ~score_df.columns.isin([\"text\"])].quantile(0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_quantile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_df = score_df\n",
    "filtered_df = filtered_df[filtered_df.upper <= mean_quantile.upper]\n",
    "filtered_df = filtered_df[filtered_df.numeric <= mean_quantile.numeric]\n",
    "filtered_df = filtered_df[filtered_df.punc <= mean_quantile.punc]\n",
    "filtered_df = filtered_df[filtered_df.newline <= mean_quantile.newline]\n",
    "\n",
    "\n",
    "# filtered_df = filtered_df[score_df.length <= mean_quantile.length]\n",
    "# filtered_df = filtered_df[filtered_df.lower <= mean_quantile.lower]\n",
    "# filtered_df = filtered_df[filtered_df.white_space <= mean_quantile.white_space]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trim to sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}